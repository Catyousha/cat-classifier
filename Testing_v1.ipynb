{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "appreciated-howard",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "direct-vanilla",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(x):\n",
    "    x /= 255.\n",
    "    x -= 0.5\n",
    "    x *= 2.\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "final-keeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"./MODEL_AWAL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adolescent-lover",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 150\n",
    "img_width = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "social-disability",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Abyssinian', 'American Bobtail', 'American Curl', 'American Shorthair', 'American Wirehair', 'Applehead Siamese', 'Balinese', 'Bengal', 'Birman', 'Bombay', 'British Shorthair', 'Burmese', 'Burmilla', 'Calico', 'Canadian Hairless', 'Chartreux', 'Chausie', 'Chinchilla', 'Cornish Rex', 'Cymric', 'Devon Rex', 'Dilute Calico', 'Dilute Tortoiseshell', 'Domestic Long Hair', 'Domestic Medium Hair', 'Domestic Short Hair', 'Egyptian Mau', 'Exotic Shorthair', 'Extra-Toes Cat - Hemingway Polydactyl', 'Havana', 'Himalayan', 'Japanese Bobtail', 'Javanese', 'Korat', 'LaPerm', 'Maine Coon', 'Manx', 'Munchkin', 'Nebelung', 'Norwegian Forest Cat', 'Ocicat', 'Oriental Long Hair', 'Oriental Short Hair', 'Oriental Tabby', 'Persian', 'Pixiebob', 'Ragamuffin', 'Ragdoll', 'Russian Blue', 'Scottish Fold', 'Selkirk Rex', 'Siamese', 'Siberian', 'Silver', 'Singapura', 'Snowshoe', 'Somali', 'Sphynx - Hairless Cat', 'Tabby', 'Tiger', 'Tonkinese', 'Torbie', 'Tortoiseshell', 'Turkish Angora', 'Turkish Van', 'Tuxedo', 'York Chocolate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "neural-channels",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://images2.minutemediacdn.com/image/upload/c_crop,h_1415,w_2103,x_8,y_0/v1612372034/shape/mentalfloss/641669-gettyimages-1182725559.jpg\n",
      "139264/138734 [==============================] - 0s 1us/step\n",
      "Domestic Short Hair 17.611976712942123 %\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import urlparse\n",
    "cat = \"https://images2.minutemediacdn.com/image/upload/c_crop,h_1415,w_2103,x_8,y_0/v1612372034/shape/mentalfloss/641669-gettyimages-1182725559.jpg\"\n",
    "a = urlparse(cat)\n",
    "file_name = os.path.basename(a.path)\n",
    "\n",
    "cat_path = tf.keras.utils.get_file(f'./{file_name}', origin=cat, cache_dir='./')\n",
    "img = keras.preprocessing.image.load_img(\n",
    "    cat_path, target_size=(img_height, img_width)\n",
    ")\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "img_array = preprocess_input(img_array)\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "print(class_names[np.argmax(score)], 1000 * (np.max(score)), \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
