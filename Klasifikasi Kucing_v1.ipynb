{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-capital",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first-housing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-tanzania",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-approach",
   "metadata": {},
   "outputs": [],
   "source": [
    "CAT_DATASET = './CAT_DATASET'\n",
    "dataset_dir = pathlib.Path(CAT_DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geographic-requirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 150\n",
    "img_width = 150\n",
    "epochs = 10\n",
    "batch_size = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-meditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                  shear_range=0.2,\n",
    "                                  zoom_range=0.2,\n",
    "                                  horizontal_flip=True,\n",
    "                                  validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authentic-earthquake",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = train_datagen.flow_from_directory(CAT_DATASET,\n",
    "                                              target_size=(img_width, img_height),\n",
    "                                              batch_size=256,\n",
    "                                              class_mode='categorical',\n",
    "                                              subset='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-burke",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_gen = train_datagen.flow_from_directory(CAT_DATASET,\n",
    "                                              target_size=(img_width, img_height),\n",
    "                                              batch_size=256,\n",
    "                                              class_mode='categorical',\n",
    "                                              subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-uzbekistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = train_gen.num_classes\n",
    "class_names = list(train_gen.class_indices.keys())\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becoming-given",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arabic-bulgaria",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base = keras.applications.inception_resnet_v2.InceptionResNetV2(weights='imagenet', \n",
    "                                                                      include_top=False, \n",
    "                                                                      input_shape=(img_width,img_height,3))\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "for layer in model_base.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.add(model_base)\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(512, activation='relu'))\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(keras.layers.Dense(67, activation='softmax'))\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-profession",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_gen,\n",
    "                    steps_per_epoch = train_gen.samples // batch_size,\n",
    "                    validation_data = val_gen, \n",
    "                    validation_steps = val_gen.samples // batch_size,\n",
    "                    epochs = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-assumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amended-fantasy",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.save('./MODEL_AWAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-applicant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(x):\n",
    "    x /= 255.\n",
    "    x -= 0.5\n",
    "    x *= 2.\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executive-dakota",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "a = urlparse(cat)\n",
    "file_name = os.path.basename(a.path)\n",
    "\n",
    "cat = \"https://cdn-2.tstatic.net/jogja/foto/bank/images/kucing-sphynx_20151213_161613.jpg\"\n",
    "cat_path = tf.keras.utils.get_file(f'./{file_name}', origin=cat, cache_dir='./')\n",
    "img = keras.preprocessing.image.load_img(\n",
    "    cat_path, target_size=(img_height, img_width)\n",
    ")\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "img_array = preprocess_input(img_array)\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "print(class_names[np.argmax(score)], round(100 * np.max(score)), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "settled-insight",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
